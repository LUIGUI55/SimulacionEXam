{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d312e6a0",
   "metadata": {},
   "source": [
    "# Division del Dataset\n",
    "En este notebook se muestran algunos de los mecanismos mas utilizados para la division del datset \n",
    "#### DataSet \n",
    "#### Descripcion\n",
    "We apologize, this dataset is no longer available.\n",
    "\n",
    "ISCX NSL-KDD is a data set suggested to solve some of the inherent problems of the KDD'99 data set which are mentioned in [1]. Although, this new version of the KDD data set still suffers from some of the problems discussed by McHugh and may not be a perfect representative of existing real networks, because of the lack of public data sets for network-based IDSs, we believe it still can be applied as an effective benchmark data set to help researchers compare different intrusion detection methods.\n",
    "\n",
    "Furthermore, the number of records in the NSL-KDD train and test sets are reasonable. This advantage makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research work will be consistent and comparable.\n",
    "\n",
    "Data files\n",
    "\n",
    "* <spam style=\"color:green\">  KDDTrain+.ARFF: The full NSL-KDD train set with binary labels in ARFF format </spam>\n",
    "* KDDTrain+.TXT: The full NSL-KDD train set including attack-type labels and difficulty level in CSV format\n",
    "* KDDTrain+_20Percent.ARFF: A 20% subset of the KDDTrain+.arff file\n",
    "* KDDTrain+_20Percent.TXT: A 20% subset of the KDDTrain+.txt file\n",
    "* KDDTest+.ARFF: The full NSL-KDD test set with binary labels in ARFF format\n",
    "* KDDTest+.TXT: The full NSL-KDD test set including attack-type labels and difficulty level in CSV format\n",
    "* KDDTest-21.ARFF: A subset of the KDDTest+.arff file which does not include records with difficulty level of 21 out of 21\n",
    "* KDDTest-21.TXT: A subset of the KDDTest+.txt file which does not include records with difficulty level of 21 out of 21\n",
    "\n",
    "[Link de Descarga](https://www.unb.ca/cic/datasets/nsl.html) \n",
    "\n",
    "License\n",
    "You may redistribute, republish, and mirror the ISCX NSL-KDD dataset in any form. However, any use or redistribution of the data must include a citation to the NSL-KDD dataset and the paper referenced below.\n",
    "\n",
    "References: [1] M. Tavallaee, E. Bagheri, W. Lu, and A. Ghorbani, “A Detailed Analysis of the KDD CUP 99 Data Set,” Submitted to Second IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA), 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52fb0f",
   "metadata": {},
   "source": [
    "## 1.- Lectura del DataSet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f9e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7689bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kdd_dataset(data_path): \n",
    "    \"\"\"Lectura del dataset NSL-KDD\"\"\"\n",
    "    with open(data_path, 'r') as train_set:\n",
    "        dataset = arff.load(train_set)\n",
    "        attributes = [attr[0] for attr in dataset[\"attributes\"]]\n",
    "    return pd.DataFrame(dataset[\"data\"], columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feeb189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   duration                     125973 non-null  float64\n",
      " 1   protocol_type                125973 non-null  object \n",
      " 2   service                      125973 non-null  object \n",
      " 3   flag                         125973 non-null  object \n",
      " 4   src_bytes                    125973 non-null  float64\n",
      " 5   dst_bytes                    125973 non-null  float64\n",
      " 6   land                         125973 non-null  object \n",
      " 7   wrong_fragment               125973 non-null  float64\n",
      " 8   urgent                       125973 non-null  float64\n",
      " 9   hot                          125973 non-null  float64\n",
      " 10  num_failed_logins            125973 non-null  float64\n",
      " 11  logged_in                    125973 non-null  object \n",
      " 12  num_compromised              125973 non-null  float64\n",
      " 13  root_shell                   125973 non-null  float64\n",
      " 14  su_attempted                 125973 non-null  float64\n",
      " 15  num_root                     125973 non-null  float64\n",
      " 16  num_file_creations           125973 non-null  float64\n",
      " 17  num_shells                   125973 non-null  float64\n",
      " 18  num_access_files             125973 non-null  float64\n",
      " 19  num_outbound_cmds            125973 non-null  float64\n",
      " 20  is_host_login                125973 non-null  object \n",
      " 21  is_guest_login               125973 non-null  object \n",
      " 22  count                        125973 non-null  float64\n",
      " 23  srv_count                    125973 non-null  float64\n",
      " 24  serror_rate                  125973 non-null  float64\n",
      " 25  srv_serror_rate              125973 non-null  float64\n",
      " 26  rerror_rate                  125973 non-null  float64\n",
      " 27  srv_rerror_rate              125973 non-null  float64\n",
      " 28  same_srv_rate                125973 non-null  float64\n",
      " 29  diff_srv_rate                125973 non-null  float64\n",
      " 30  srv_diff_host_rate           125973 non-null  float64\n",
      " 31  dst_host_count               125973 non-null  float64\n",
      " 32  dst_host_srv_count           125973 non-null  float64\n",
      " 33  dst_host_same_srv_rate       125973 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       125973 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  125973 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  125973 non-null  float64\n",
      " 37  dst_host_serror_rate         125973 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     125973 non-null  float64\n",
      " 39  dst_host_rerror_rate         125973 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     125973 non-null  float64\n",
      " 41  class                        125973 non-null  object \n",
      "dtypes: float64(34), object(8)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = load_kdd_dataset(\"../datasets/NSL-KDD/KDDTrain+.arff\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e84f42",
   "metadata": {},
   "source": [
    "## Division del dataset \n",
    "Se debe separar el dataset en los diferentes subconjuntos necesarios para realizar los procesos de entrenamiento, validacion y pruebas. Sklearn tiene implemnetado la funcion **split_test_split**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531d63fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos el datset 60% train set, 40% test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c71455ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 75583 entries, 98320 to 121958\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     75583 non-null  float64\n",
      " 1   protocol_type                75583 non-null  object \n",
      " 2   service                      75583 non-null  object \n",
      " 3   flag                         75583 non-null  object \n",
      " 4   src_bytes                    75583 non-null  float64\n",
      " 5   dst_bytes                    75583 non-null  float64\n",
      " 6   land                         75583 non-null  object \n",
      " 7   wrong_fragment               75583 non-null  float64\n",
      " 8   urgent                       75583 non-null  float64\n",
      " 9   hot                          75583 non-null  float64\n",
      " 10  num_failed_logins            75583 non-null  float64\n",
      " 11  logged_in                    75583 non-null  object \n",
      " 12  num_compromised              75583 non-null  float64\n",
      " 13  root_shell                   75583 non-null  float64\n",
      " 14  su_attempted                 75583 non-null  float64\n",
      " 15  num_root                     75583 non-null  float64\n",
      " 16  num_file_creations           75583 non-null  float64\n",
      " 17  num_shells                   75583 non-null  float64\n",
      " 18  num_access_files             75583 non-null  float64\n",
      " 19  num_outbound_cmds            75583 non-null  float64\n",
      " 20  is_host_login                75583 non-null  object \n",
      " 21  is_guest_login               75583 non-null  object \n",
      " 22  count                        75583 non-null  float64\n",
      " 23  srv_count                    75583 non-null  float64\n",
      " 24  serror_rate                  75583 non-null  float64\n",
      " 25  srv_serror_rate              75583 non-null  float64\n",
      " 26  rerror_rate                  75583 non-null  float64\n",
      " 27  srv_rerror_rate              75583 non-null  float64\n",
      " 28  same_srv_rate                75583 non-null  float64\n",
      " 29  diff_srv_rate                75583 non-null  float64\n",
      " 30  srv_diff_host_rate           75583 non-null  float64\n",
      " 31  dst_host_count               75583 non-null  float64\n",
      " 32  dst_host_srv_count           75583 non-null  float64\n",
      " 33  dst_host_same_srv_rate       75583 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       75583 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  75583 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  75583 non-null  float64\n",
      " 37  dst_host_serror_rate         75583 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     75583 non-null  float64\n",
      " 39  dst_host_rerror_rate         75583 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     75583 non-null  float64\n",
      " 41  class                        75583 non-null  object \n",
      "dtypes: float64(34), object(8)\n",
      "memory usage: 24.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc6f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar el datset de pruebas 50% para validation_set y 50% para test_set\n",
    "val_set, test_set = train_test_split(test_set, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28108bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del Training Set: 75583\n",
      "Longitud del Validation set: 25195\n",
      "Longitud del Test set: 25195\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud del Training Set:\", len(train_set))\n",
    "print(\"Longitud del Validation set:\", len(val_set))\n",
    "print(\"Longitud del Test set:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ac377f",
   "metadata": {},
   "source": [
    "## 3.- Particionado aleatorio y Stratified Sampling\n",
    "\n",
    "Sklearn tiene implemetada la funcion **train_test_split**, sin simbargo, esta funcion por defecto realiza un paticionado de datos aleatorio para cada vez que se ejecuta el script. Aun anadiendo una semilla fija para generacion aleatoria, cada vez que se cargue nuevamente el conjunto de datos se generaran nuevos subcojuntos. Esto puede ocasionar que despues de muchso intentos el algoritmo **\"vea\"** todo el  conjunto de datos. \n",
    "\n",
    "Para sloucionar este problema Sklearn ha introducido el parametro **shuffle** en la funcion **train_test_split**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106663ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si shuffle es = a false el dataset no mezclara antes del particionado \n",
    "train_set, test_set = train_test_split(df, test_size=0.4, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4cab96",
   "metadata": {},
   "source": [
    "Estos metodos para dividir el dataset estan bien si tienes un conjunto de datos muy grande, pero si no se tiene, se corre el riesgo de introducir **Sampling bias**.\n",
    "\n",
    "Para evitar esto se utiliza un metodo de sampling que se llama **Stratified Sampling**. La poblacion es dividida en subconjuntos homogeneos llamados **strata**. El objetivo es que no quede ninguna caracteristica del conjunto de datos sin representacion en ninguno de los conjuntos de datos para una o mas caracteristicas en particular.\n",
    "\n",
    "sklearn introduce el parametro **Stratify** en la funcion train_test_split para controlar este comportamiento. \n",
    "\n",
    "_This Stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to paramete stratify._\n",
    "_For example, if variable y is a binary categorical variable with values 0 and 1 there 25% of zeros 75% of ones, stratify = y will make sure that your random split has 25% of 0's and 75% 1's._\n",
    "\n",
    "_https://stackoverflow.com_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
